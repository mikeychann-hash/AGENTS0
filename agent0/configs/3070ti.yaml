# ============================================
# LOCAL DEVELOPMENT CONFIGURATION
# ============================================
# WARNING: No sandboxing or isolation!
# Code runs directly on your machine.
# Only use with trusted tasks.
# ============================================

# 3070 Ti-friendly defaults (8 GB VRAM target).
models:
  teacher:
    backend: ollama
    model: qwen2.5:3b
    host: http://127.0.0.1:11434
    context_length: 4096
    temperature: 0.7
    top_p: 0.9
    uncertainty_samples: 3
  student:
    backend: ollama
    model: qwen2.5:7b
    host: http://127.0.0.1:11434
    context_length: 8192
    temperature: 0.6
    top_p: 0.9
    uncertainty_samples: 3

resources:
  device: cuda
  max_gpu_memory_gb: 8
  num_threads: 6
  max_tokens_per_task: 512

tooling:
  # LOCAL MODE: Limited tools for safety
  enable_python: true
  enable_shell: false
  enable_math: true
  enable_tests: false
  timeout_seconds: 30
  workdir: ./sandbox
  allowed_shell: []

rewards:
  weight_uncertainty: 0.5
  weight_tool_use: 0.3
  weight_novelty: 0.2
  target_success_rate: 0.5
  repetition_similarity_threshold: 0.9

# ============================================
# NEW: Enhanced Curriculum Scheduler
# ============================================
curriculum:
  # Frontier-based domain selection (chooses domains at learning boundary)
  enable_frontier: true
  
  # Target success rate (0.5 = 50% - optimal for learning)
  target_success: 0.5
  
  # Acceptable range around target (0.5 +/- 0.1 = 40-60%)
  frontier_window: 0.1
  
  # Domains to train on
  domains:
    - math
    - logic
    - code

# ============================================
# NEW: Self-Verification System
# ============================================
verification:
  # Enable self-verification (generates multiple solutions for consensus)
  enable: false  # Set to true to enable
  
  # Number of solutions to generate for voting
  num_samples: 3
  
  # Minimum agreement rate to accept (0.7 = 70%)
  confidence_threshold: 0.7
  
  # Add "think step by step" to verification prompts
  enable_cot: true

logging:
  base_dir: ./runs
  save_every: 10
  flush_every: 1

router:
  enable: true
  cloud_confidence_threshold: 0.7
  local_confidence_threshold: 0.4
  cache_path: ./runs/router_cache.json
  cloud_command: ""  # e.g., openai api chat.completions.create -m gpt-4o-mini

embedding:
  use_transformer: true
  model_name: all-MiniLM-L6-v2

# ============================================
# NEW: Security and Rate Limiting
# ============================================
rate_limiting:
  # Maximum tasks per minute (prevents abuse)
  max_tasks_per_minute: 30
  
  # Maximum tasks per hour (prevents long-term abuse)
  max_tasks_per_hour: 1000

# ============================================
# NEW: Resource Limits
# ============================================
resource_limits:
  # Maximum memory usage per task (MB)
  max_memory_mb: 512
  
  # Maximum CPU time per task (seconds)
  max_cpu_seconds: 30
  
  # Maximum output size per task (KB)
  max_output_kb: 100
